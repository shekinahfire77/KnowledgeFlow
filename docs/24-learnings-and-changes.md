# Learnings and Changes: Stage 2

Version: 0.1
Owner: research-lead
Status: Draft - To be updated throughout Stage 2 and finalized Nov 14, 2025
Last updated: 2025-10-31

---

## Purpose

This document tracks all adjustments, deviations, insights, and learnings from Stage 2. It serves as:
1. A record of what changed from the original plan and why
2. Documented learnings for future stages and research
3. Transparency log for methodology decisions
4. Input for continuous improvement

---

## VALUE PROPOSITION CHANGES

### Original (from Stage 1 - /docs/05-value-proposition.md)

"[Copy original value proposition here after analysis]"

### Updated (based on Stage 2 validation)

"[New version after analyzing what resonated]"

**Example structure:**
> "KnowledgeFlow helps knowledge workers who juggle multiple note-taking tools by automatically discovering connections in their notes using local AI—keeping your data private while saving 30+ minutes per day on context-switching."

### Changes Made

1. **[Change 1 - e.g., "Lead with privacy instead of productivity"]**
   - Rationale: [e.g., "80% of participants rated privacy 9-10/10; strongest resonance in concept card reactions"]
   - Evidence: [Quote or data reference]

2. **[Change 2 - e.g., "Quantify time savings (30+ minutes) instead of vague 'better workflow'"]**
   - Rationale: [e.g., "Median participant lost 45 min/day; specific number creates urgency"]
   - Evidence: [Data reference]

3. **[Change 3 - e.g., "Use 'discover connections' language instead of 'create links'"]**
   - Rationale: [e.g., "Participants used 'connections' naturally; 'links' sounds manual"]
   - Evidence: [Coded excerpts showing language patterns]

---

## PERSONA REFINEMENTS

### Rachel (Research Analyst)

**What We Learned That Differed from Draft:**

1. **[Learning 1 - e.g., "Regulatory compliance (GDPR, HIPAA) is a bigger concern than general 'confidentiality'"]**
   - Original persona: [What we assumed]
   - Actual finding: [What we learned from P001, P004, P007]
   - Update needed: [Add compliance pain point, mention specific regulations]

2. **[Learning 2 - e.g., "WTP higher than estimated"]**
   - Original estimate: [$5-10/month]
   - Actual median: [$12/month for Rachel segment]
   - Update needed: [Adjust persona WTP range]

3. **[Learning 3 - e.g., "Client project context-switching is #1 pain, not tool limitations"]**
   - Original emphasis: [Tool feature gaps]
   - Actual pain: [Mental overhead switching between 5+ simultaneous client projects]
   - Update needed: [Reframe pain story to emphasize project juggling]

**Updated Background Quote:**
Original: "[Draft quote]"
New (from P001): "[Actual quote from interview that captures Rachel's experience]"

**New Pain Points to Add:**
- [Pain point 1]
- [Pain point 2]

**Tools Actually Used** (vs assumed):
- Original: [Assumed tools]
- Actual: [Most common combination from interviews - e.g., "Notion (client collaboration) + Obsidian (private notes) + OneNote (meeting notes)"]

---

### Finn (Freelance Creator)

**What We Learned That Differed:**

1. **[Learning 1]**
   - Original:
   - Actual:
   - Update:

2. **[Learning 2]**

3. **[Learning 3]**

**Updated Background Quote:**

**New Pain Points:**

**Tools Actually Used:**

---

### Gia (Graduate Student)

**What We Learned That Differed:**

1. **[Learning 1 - e.g., "Citation management pain more acute than note organization"]**
   - Original:
   - Actual:
   - Update:

2. **[Learning 2 - e.g., "Price sensitivity extreme: $3-5/month max, not $5-10"]**
   - Original:
   - Actual:
   - Update:

3. **[Learning 3]**

**Updated Background Quote:**

**New Pain Points:**

**Tools Actually Used:**

---

## FEATURE PRIORITIZATION CHANGES

### Must-Have (Blocking) - Updated

**Original list:**
1. [Original must-have 1]
2. [Original must-have 2]
3. [Original must-have 3]

**Updated list after validation:**

1. **[Feature 1 - e.g., "Local-first storage / offline-first"]**
   - Evidence: [#]/10 mentioned as dealbreaker, code PAIN-005, PAIN-006
   - Status: [Confirm as must-have / New addition / Unchanged]

2. **[Feature 2 - e.g., "Auto-linking / semantic suggestions"]**
   - Evidence: [#]/10 mentioned, [##]% in concept card reaction
   - Status: [Elevated from nice-to-have / Unchanged]

3. **[Feature 3 - e.g., "Notion and Obsidian import"]**
   - Evidence: [#]/10 said dealbreaker
   - Status: [NEW - not in original must-have list]

4. **[Feature 4]**

---

### High-Value (Differentiating) - Updated

**Original list:**
1. [Original high-value 1]
2. [Original high-value 2]

**Updated list:**

1. **[Feature 1 - e.g., "Graph visualization"]**
   - Evidence: [#]/10 mentioned
   - Status: [Demoted from must-have to high-value based on data]
   - Rationale: [e.g., "Only 4/10 mentioned; nice-to-have but not blocking"]

2. **[Feature 2]**

---

### Nice-to-Have - Deprioritized

**Features moved to v1.1 or later:**

1. **[Feature 1 - e.g., "Collaboration / shared notes"]**
   - Evidence: [Only 1/10 mentioned; privacy-focused users prefer solo]
   - Status: [Demoted from high-value]
   - Rationale: [Conflicts with privacy positioning; revisit post-launch]

2. **[Feature 2 - e.g., "Handwriting input"]**
   - Evidence: [Only 1/10 mentioned]
   - Status: [Defer to v2]

---

### New Additions (Not in Original Plan)

**Features that emerged from interviews:**

1. **[Feature - e.g., "Advanced search with filters (date, tag, project)"]**
   - Evidence: [#]/10 participants described elaborate search needs
   - Priority: [Must-have / High-value]
   - Why we missed this: [Assumed basic search was enough; underestimated search complexity]

2. **[Feature 2]**

---

## HYPOTHESES VALIDATION SUMMARY

### Strongly Validated (Exceeded Expectations)

**[Hypothesis ID - e.g., H2]: Privacy blocks 40%+ from cloud tools**
- Target: ≥40% privacy-sensitive
- Actual: [##]% (PRIV-001)
- Exceeded by: [##] percentage points
- Insight: [What this means - e.g., "Privacy is a stronger differentiator than anticipated; should be primary positioning"]

**[Hypothesis ID]:**

---

### Validated (Met Expectations)

**[Hypothesis ID]:**
- Target:
- Actual:
- Status: Met

---

### Weakly Validated (Below Expectations but Directionally Correct)

**[Hypothesis ID]:**
- Target:
- Actual:
- Gap:
- Insight: [Why we missed; still directionally useful?]

---

### Invalidated (Failed to Validate)

**[Hypothesis ID - e.g., H9]: Import required by 70%+**
- Target: ≥70% need import
- Actual: [##]%
- Gap: [Missed by X percentage points]
- Insight: [What this means - e.g., "Import is important but not universal; segment-dependent (critical for Rachel/Finn, less for Gia)"]
- Action: [Still build import but adjust messaging]

---

### New Hypotheses Generated

**[New hypothesis from data]:**
- Observation: [What we saw]
- Hypothesis: [What we now believe]
- Test in: [Stage 3 / Future research]

---

## RISKS ADDED

**[Risk ID - e.g., R13]: Import complexity underestimated**

**Description:**
[What is the risk? - e.g., "Notion and Obsidian use different formats (JSON, Markdown); mapping databases, tags, and links may be lossy or break structure. 60% of participants use Notion with complex databases."]

**Source:**
[Which interviews or observations - e.g., "P002, P005, P007, P009 all mentioned import as dealbreaker; P002 showed 50+ interconnected database entries"]

**Likelihood:** [High]
**Impact:** [High - could block adoption]
**Priority:** [Critical]

**Mitigation:**
1. [Mitigation step 1 - e.g., "Technical spike: build prototype importer for Notion and Obsidian"]
2. [Mitigation step 2 - e.g., "Test with real user data (with permission)"]
3. [Mitigation step 3 - e.g., "Accept lossy import if necessary; provide manual cleanup guide"]
4. [Mitigation step 4 - e.g., "Allocate 2 sprints (20% of MVP timeline) to import feature"]

**Owner:** [technical-lead]

---

**[Risk ID]:** [Another new risk]
[Same structure]

---

## RISKS RETIRED

**[Risk ID - e.g., R03]: Local AI accuracy concerns**

**Original description:**
[What we thought was a risk - e.g., "Users won't trust AI running locally; will prefer cloud-based solutions with better models"]

**Why retired:**
[Evidence that risk didn't materialize - e.g., "No participants expressed AI accuracy concerns; 7/10 were enthusiastic about local AI for privacy. Trust in local AI higher than cloud AI."]

**Status:** [Retired / Deprioritized to low]

---

## METHODOLOGY LEARNINGS

### What Worked Well

1. **[What worked - e.g., "Last-time narrative technique"]**
   - Description: [Asking participants to walk through the last time they took notes]
   - Why it worked: [Produced rich, specific stories with concrete pain points; avoided abstract generalizations]
   - Evidence: [8/10 interviews had vivid stories; coded 3-5 excerpts per story]
   - Apply in future: [Use for all behavioral interviews]

2. **[What worked - e.g., "Reddit recruitment outperformed LinkedIn"]**
   - Description: [Reddit r/Obsidian and r/productivity generated 60% of qualified responses]
   - Why it worked: [Niche communities already engaged with topic; higher pain awareness]
   - Evidence: [Reddit: 24 qualified from 30 responses (80%); LinkedIn: 8 qualified from 25 responses (32%)]
   - Apply in future: [Prioritize niche subreddits; expand to r/PKMS, r/RoamResearch]

3. **[What worked]**

---

### What to Improve

1. **[Improvement area - e.g., "Screener should have asked about import needs explicitly"]**
   - What we did: [Only asked about tools used, not whether import is important]
   - What went wrong: [Import emerged as critical (60% mentioned) but we didn't screen for it; couldn't ensure quota of import-sensitive users]
   - How to fix: [Add screener question: "If you switched tools, how important is importing your existing notes? (1-5 scale)"]

2. **[Improvement area - e.g., "Attention-check question too easy"]**
   - What we did: ["Please select 'Somewhat agree' for this question"]
   - What went wrong: [100% pass rate; didn't filter out bots or inattentive respondents effectively]
   - How to fix: [Use harder attention check: "How many hours are in a day? (Options: 12, 18, 24, 36)" or "What color is mentioned in this survey? [none mentioned]"]

3. **[Improvement area - e.g., "WTP question needed anchoring"]**
   - What we did: [Open-ended "What would you pay per month?"]
   - What went wrong: [Wide variance ($0-$30); hard to interpret; some participants confused]
   - How to fix: [Use Van Westendorp pricing model: Ask "Too cheap", "Cheap", "Expensive", "Too expensive" for each price point]

4. **[Improvement area]**

---

### Deviations from Plan

**[Deviation 1 - e.g., "Extended recruitment by 2 days"]**
- **Plan:** Close screener Nov 4
- **Actual:** Closed Nov 6
- **Reason:** [Only 32 qualified responses by Nov 4; needed 40+; Gia segment under-represented]
- **Impact:** [Pushed interview start to Nov 8; compressed analysis timeline by 1 day]
- **Mitigation:** [Worked weekend to catch up; still completed on time]

**[Deviation 2 - e.g., "Interviewed 9 instead of 10"]**
- **Plan:** 10 interviews
- **Actual:** 9 interviews
- **Reason:** [P010 no-showed twice; no backup available in Finn segment]
- **Impact:** [Slightly below target but quotas still met (Rachel 3, Finn 2, Gia 2, Other 2)]
- **Mitigation:** [Deemed acceptable; data saturation reached by interview 8]

**[Deviation 3]**

---

## COMPETITIVE INSIGHTS

### New Competitors Identified

**[Tool name - e.g., "Mem"]**
- **How discovered:** [Mentioned by P003, P008]
- **What it does:** [AI-powered note-taking with auto-tagging]
- **Why relevant:** [Competes on automation angle]
- **How we differentiate:** [Local AI vs cloud; privacy-first]

**[Tool name]**

---

### Competitive Positioning Adjustments

**Original positioning:**
"[How we thought we'd position vs competitors]"

**Updated positioning based on actual user comparisons:**

**vs Obsidian:**
- Original: [Easier to use, less manual linking]
- Updated: [Automatic linking (vs manual); local AI (vs plugins); privacy-first (same)]
- User language: ["Obsidian is powerful but tedious; I want the graph without the work"]

**vs Notion:**
- Original: [Better for individual knowledge work, not collaboration]
- Updated: [Privacy-first (vs cloud risk); offline-first (vs sync issues); faster (vs slow load)]
- User language: ["Notion is great for teams but I don't trust it with client data"]

**vs OneNote:**
- Original: [More flexible, better linking]
- Updated: [Semantic organization (vs rigid notebooks); AI-powered (vs manual); multi-tool bridge (vs silo)]
- User language: ["OneNote forces structure; I think in networks not hierarchies"]

---

## PRICING INSIGHTS

### Willingness-to-Pay Drivers

**What increases WTP (correlations observed):**

1. **[Driver 1 - e.g., "Privacy importance"]**
   - Observation: [Participants rating privacy 9-10/10 had median WTP of $X vs $Y overall]
   - Correlation strength: [Strong / Moderate / Weak]
   - Implication: [Privacy-focused users are premium segment; emphasize in messaging to high-WTP audience]

2. **[Driver 2 - e.g., "Time lost to context-switching"]**
   - Observation: [Participants losing >1hr/day had median WTP of $X vs $Y for <30min/day]
   - Correlation strength:
   - Implication: [Quantify time savings in value prop; calculator on landing page?]

3. **[Driver 3 - e.g., "Professional use case (vs academic)"]**
   - Observation: [Rachel/Finn median $X vs Gia median $Y]
   - Correlation strength:
   - Implication: [Student pricing necessary; professional pricing sustainable]

---

### Price Resistance Factors

**What decreases WTP:**

1. **[Factor 1 - e.g., "Student status"]**
   - Observation: [Gia segment median WTP $4/month vs $8 overall]
   - Implication: [Offer student discount (50%) or free tier with limits]

2. **[Factor 2 - e.g., "Using Obsidian (free) currently"]**
   - Observation: [5/10 used Obsidian; median WTP $6 vs $9 for non-Obsidian users]
   - Implication: [Free anchor effect; emphasize automation value (what Obsidian lacks)]

3. **[Factor 3 - e.g., "Perception of 'just a note app'"]**
   - Observation: [Participants who said "it's just notes" had lower WTP]
   - Implication: [Frame as knowledge management / research tool, not note-taking]

---

### Recommended Pricing Strategy

**Launch price:** $[#]/month (based on data)

**Rationale:**
1. [Aligns with median WTP]
2. [Captures X% of market willing to pay]
3. [Positions competitively vs Notion/Evernote/Roam]

**Pricing model:** [Freemium / Paid-only / Free trial + paid]

**Student pricing:** [Yes - $X/month (50% discount) / No]

**Future price increases:**
- [When to increase - e.g., "After 1000 users, increase to $X"]
- [Grandfathering - e.g., "Grandfather early adopters at launch price"]

---

## SEGMENTATION INSIGHTS

### Segment Overlap and Distinctiveness

**Clear differences between segments:**
- [e.g., "Rachel prioritizes privacy (90% rated 9-10) vs Finn prioritizes multi-project management (80%)"]
- [e.g., "Gia has lower WTP ($4) vs Rachel/Finn ($10-12)"]

**Surprising similarities across segments:**
- [e.g., "All segments mentioned context-switching pain (100%); universal problem"]
- [e.g., "Auto-linking resonated equally (Rachel 100%, Finn 100%, Gia 100%)"]

**Recommendation:**
- [Should we build one product for all or segment-specific versions?]
- [Current recommendation: Single product, segment-specific messaging]

---

## OPEN QUESTIONS FOR STAGE 3

**Questions generated by Stage 2 findings:**

1. **[Question - e.g., "What accuracy threshold makes auto-linking 'magical' vs 'annoying'?"]**
   - Why it emerged: [Participants excited about auto-linking but assume it "just works"; no tolerance discussion]
   - How to answer in Stage 3: [Prototype test with varying accuracy (50%, 70%, 90%); measure satisfaction]

2. **[Question - e.g., "Will users actually import existing notes or start fresh?"]**
   - Why it emerged: [60% said import is dealbreaker, but only 2/10 mentioned volume of existing notes]
   - How to answer: [Ask beta testers; track actual import usage post-launch]

3. **[Question - e.g., "Is 'privacy' a genuine preference or a stated preference?"]**
   - Why it emerged: [High stated privacy importance (80% rated 9-10) but 90% use cloud tools currently]
   - How to answer: [A/B test messaging; measure conversion with privacy-led vs productivity-led]

4. **[Question]**

5. **[Question]**

---

## TIMELINE NOTES

### Actual vs Planned

| Milestone | Planned | Actual | Variance | Reason |
|-----------|---------|--------|----------|--------|
| Screener launch | Nov 1 | [Nov X] | [+/- X days] | [Reason if delayed] |
| Screener close | Nov 4 | [Nov X] | [+/- X days] | [e.g., "Extended for Gia quota"] |
| Interviews start | Nov 6 | [Nov X] | [+/- X days] | [Reason] |
| Interviews complete | Nov 11 | [Nov X] | [+/- X days] | [e.g., "No-show rescheduling"] |
| Coding complete | Nov 12 | [Nov X] | [+/- X days] | [Reason] |
| Analysis complete | Nov 13 | [Nov X] | [+/- X days] | [Reason] |
| Decision memo | Nov 14 | [Nov X] | [+/- X days] | [Reason] |

**Overall timeline:** [On track / Delayed by X days / Early by X days]

**Total Stage 2 duration:** [Planned: 14 days] [Actual: X days]

---

### Delays and Causes

**[Delay 1 - if applicable]:**
- Task: [e.g., "Recruitment"]
- Planned: [Date]
- Actual: [Date]
- Delay: [X days]
- Cause: [e.g., "Slow Gia segment response from university mailing lists"]
- Mitigation: [e.g., "Expanded to Reddit r/GradSchool"]
- Preventable?: [Yes / No - how]

**[Delay 2]:**

---

## DATA SECURITY INCIDENTS

[Log any incidents here, even if resolved. If none, write "None."]

**Incident 1: [Date]** [If applicable]
- What happened: [Description]
- Data exposed: [What PII or sensitive data]
- Duration of exposure: [How long]
- Affected participants: [N participants or "none confirmed"]
- Remediation: [What we did - e.g., "Removed from repo history via BFG"]
- Notification: [Were participants notified? When?]
- Prevention: [What changed to prevent recurrence]

**Status:** [None / See above]

---

## PROCESS IMPROVEMENTS FOR FUTURE STAGES

### What to Repeat

1. [Process element 1]
2. [Process element 2]

### What to Change

1. [Change 1]
2. [Change 2]

### New Additions

1. [New process element to add]
2. [New element]

---

## INTER-CODER RELIABILITY CHECK

**Method:**
[Describe - e.g., "Self-check: Re-coded P002 and P006 after 48 hours without looking at original codes"]

**Results:**
- Agreement on primary codes: [##]% ([#]/[#] excerpts matched)
- Disagreements: [List code pairs that differed - e.g., "PAIN-001 vs PAIN-008 in 2 cases"]
- Resolution: [How resolved - e.g., "Refined PAIN-008 definition to exclude explicit time mentions; those are PAIN-001"]

**Code refinements made:**
- [Code ID]: [What changed in definition]
- [Code ID]: [What changed]

**Target:** >80% agreement
**Achieved:** [Yes / No]

---

## MISCELLANEOUS NOTES

[Any other observations, insights, or notes that don't fit above categories]

**[Note 1]:**

**[Note 2]:**

---

**Learnings Document Finalized:**
- Date: [Nov 14, 2025]
- Owner: research-lead
- Status: [Complete]
- Version: 1.0
